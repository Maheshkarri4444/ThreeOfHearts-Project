{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxTpRQuZUD4H",
    "outputId": "3b121bbb-c081-423d-9eaf-5009c102c3c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=54f87b3d2ac10c199a5cd83acd9a14550766444461d3df82b5e6c7323b939b36\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "import wget\n",
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "import typing\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jLotSJBAUJ90"
   },
   "outputs": [],
   "source": [
    "\n",
    "def loadvideo(filename: str) -> np.ndarray:\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(filename)\n",
    "    capture = cv2.VideoCapture(filename)\n",
    "    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    v = np.zeros((frame_count, frame_height, frame_width, 3), np.uint8)\n",
    "    for count in range(frame_count):\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            raise ValueError(\"Failed to load frame #{} of {}.\".format(count, filename))\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        v[count, :, :] = frame\n",
    "    v = v.transpose((3, 0, 1, 2))\n",
    "    return v\n",
    "\n",
    "\n",
    "def savevideo(filename: str, array: np.ndarray, fps: typing.Union[float, int] = 1):\n",
    "    c, _, height, width = array.shape\n",
    "    if c != 3:\n",
    "        raise ValueError(\"savevideo expects array of shape (channels=3, frames, height, width), got shape ({})\".format(\", \".join(map(str, array.shape))))\n",
    "    fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "    out = cv2.VideoWriter(filename, fourcc, fps, (width, height))\n",
    "    for frame in array.transpose((1, 2, 3, 0)):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        out.write(frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bootstrap(a, b, func, samples=10000):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    bootstraps = []\n",
    "    for _ in range(samples):\n",
    "        ind = np.random.choice(len(a), len(a))\n",
    "        bootstraps.append(func(a[ind], b[ind]))\n",
    "    bootstraps = sorted(bootstraps)\n",
    "    return func(a, b), bootstraps[round(0.05 * len(bootstraps))], bootstraps[round(0.95 * len(bootstraps))]\n",
    "\n",
    "\n",
    "def latexify():\n",
    "    params = {'backend': 'pdf',\n",
    "              'axes.titlesize': 8,\n",
    "              'axes.labelsize': 8,\n",
    "              'font.size': 8,\n",
    "              'legend.fontsize': 8,\n",
    "              'xtick.labelsize': 8,\n",
    "              'ytick.labelsize': 8,\n",
    "              'font.family': 'DejaVu Serif',\n",
    "              'font.serif': 'Computer Modern',\n",
    "              }\n",
    "    matplotlib.rcParams.update(params)\n",
    "\n",
    "\n",
    "def dice_similarity_coefficient(inter, union):\n",
    "    return 2 * sum(inter) / (sum(union) + sum(inter))\n",
    "\"\"\"EchoNet-Dynamic Dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "import collections\n",
    "import pandas\n",
    "\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import torchvision\n",
    "\n",
    "\n",
    "\n",
    "class Echo(torchvision.datasets.VisionDataset):\n",
    "\n",
    "    def __init__(self, root=None,\n",
    "                 split=\"train\", target_type=\"EF\",\n",
    "                 mean=0., std=1.,\n",
    "                 length=16, period=2,\n",
    "                 max_length=250,\n",
    "                 clips=1,\n",
    "                 pad=None,\n",
    "                 noise=None,\n",
    "                 target_transform=None,\n",
    "                 external_test_location=None):\n",
    "        if root is None:\n",
    "            root = \"/content/EchoNet-Dynamic\"\n",
    "\n",
    "        super().__init__(root, target_transform=target_transform)\n",
    "\n",
    "        self.split = split.upper()\n",
    "        if not isinstance(target_type, list):\n",
    "            target_type = [target_type]\n",
    "        self.target_type = target_type\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.length = length\n",
    "        self.max_length = max_length\n",
    "        self.period = period\n",
    "        self.clips = clips\n",
    "        self.pad = pad\n",
    "        self.noise = noise\n",
    "        self.target_transform = target_transform\n",
    "        self.external_test_location = external_test_location\n",
    "\n",
    "        self.fnames, self.outcome = [], []\n",
    "\n",
    "        if self.split == \"EXTERNAL_TEST\":\n",
    "            self.fnames = sorted(os.listdir(self.external_test_location))\n",
    "        else:\n",
    "            # Load video-level labels\n",
    "            with open(os.path.join(self.root, \"FileList.csv\")) as f:\n",
    "                data = pandas.read_csv(f)\n",
    "            data[\"Split\"].map(lambda x: x.upper())\n",
    "\n",
    "            if self.split != \"ALL\":\n",
    "                data = data[data[\"Split\"] == self.split]\n",
    "\n",
    "            self.header = data.columns.tolist()\n",
    "            self.fnames = data[\"FileName\"].tolist()\n",
    "            self.fnames = [fn + \".avi\" for fn in self.fnames if os.path.splitext(fn)[1] == \"\"]  # Assume avi if no suffix\n",
    "            self.outcome = data.values.tolist()\n",
    "\n",
    "            # Check that files are present\n",
    "            missing = set(self.fnames) - set(os.listdir(os.path.join(self.root, \"Videos\")))\n",
    "            if len(missing) != 0:\n",
    "                print(\"{} videos could not be found in {}:\".format(len(missing), os.path.join(self.root, \"Videos\")))\n",
    "                for f in sorted(missing):\n",
    "                    print(\"\\t\", f)\n",
    "                raise FileNotFoundError(os.path.join(self.root, \"Videos\", sorted(missing)[0]))\n",
    "\n",
    "            # Load traces\n",
    "            self.frames = collections.defaultdict(list)\n",
    "            self.trace = collections.defaultdict(_defaultdict_of_lists)\n",
    "\n",
    "            with open(os.path.join(self.root, \"VolumeTracings.csv\")) as f:\n",
    "                header = f.readline().strip().split(\",\")\n",
    "                assert header == [\"FileName\", \"X1\", \"Y1\", \"X2\", \"Y2\", \"Frame\"]\n",
    "\n",
    "                for line in f:\n",
    "                    filename, x1, y1, x2, y2, frame = line.strip().split(',')\n",
    "                    x1 = float(x1)\n",
    "                    y1 = float(y1)\n",
    "                    x2 = float(x2)\n",
    "                    y2 = float(y2)\n",
    "                    frame = int(frame)\n",
    "                    if frame not in self.trace[filename]:\n",
    "                        self.frames[filename].append(frame)\n",
    "                    self.trace[filename][frame].append((x1, y1, x2, y2))\n",
    "            for filename in self.frames:\n",
    "                for frame in self.frames[filename]:\n",
    "                    self.trace[filename][frame] = np.array(self.trace[filename][frame])\n",
    "\n",
    "            # A small number of videos are missing traces; remove these videos\n",
    "            keep = [len(self.frames[f]) >= 2 for f in self.fnames]\n",
    "            self.fnames = [f for (f, k) in zip(self.fnames, keep) if k]\n",
    "            self.outcome = [f for (f, k) in zip(self.outcome, keep) if k]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Find filename of video\n",
    "        if self.split == \"EXTERNAL_TEST\":\n",
    "            video = os.path.join(self.external_test_location, self.fnames[index])\n",
    "        elif self.split == \"CLINICAL_TEST\":\n",
    "            video = os.path.join(self.root, \"ProcessedStrainStudyA4c\", self.fnames[index])\n",
    "        else:\n",
    "            video = os.path.join(self.root, \"Videos\", self.fnames[index])\n",
    "\n",
    "        # Load video into np.array\n",
    "        video = loadvideo(video).astype(np.float32)\n",
    "\n",
    "        # Add simulated noise (black out random pixels)\n",
    "        # 0 represents black at this point (video has not been normalized yet)\n",
    "        if self.noise is not None:\n",
    "            n = video.shape[1] * video.shape[2] * video.shape[3]\n",
    "            ind = np.random.choice(n, round(self.noise * n), replace=False)\n",
    "            f = ind % video.shape[1]\n",
    "            ind //= video.shape[1]\n",
    "            i = ind % video.shape[2]\n",
    "            ind //= video.shape[2]\n",
    "            j = ind\n",
    "            video[:, f, i, j] = 0\n",
    "\n",
    "        # Apply normalization\n",
    "        if isinstance(self.mean, (float, int)):\n",
    "            video -= self.mean\n",
    "        else:\n",
    "            video -= self.mean.reshape(3, 1, 1, 1)\n",
    "\n",
    "        if isinstance(self.std, (float, int)):\n",
    "            video /= self.std\n",
    "        else:\n",
    "            video /= self.std.reshape(3, 1, 1, 1)\n",
    "\n",
    "        # Set number of frames\n",
    "        c, f, h, w = video.shape\n",
    "        if self.length is None:\n",
    "            # Take as many frames as possible\n",
    "            length = f // self.period\n",
    "        else:\n",
    "            # Take specified number of frames\n",
    "            length = self.length\n",
    "\n",
    "        if self.max_length is not None:\n",
    "            # Shorten videos to max_length\n",
    "            length = min(length, self.max_length)\n",
    "\n",
    "        if f < length * self.period:\n",
    "            # Pad video with frames filled with zeros if too short\n",
    "            # 0 represents the mean color (dark grey), since this is after normalization\n",
    "            video = np.concatenate((video, np.zeros((c, length * self.period - f, h, w), video.dtype)), axis=1)\n",
    "            c, f, h, w = video.shape  # pylint: disable=E0633\n",
    "\n",
    "        if self.clips == \"all\":\n",
    "            # Take all possible clips of desired length\n",
    "            start = np.arange(f - (length - 1) * self.period)\n",
    "        else:\n",
    "            # Take random clips from video\n",
    "            start = np.random.choice(f - (length - 1) * self.period, self.clips)\n",
    "\n",
    "        # Gather targets\n",
    "        target = []\n",
    "        for t in self.target_type:\n",
    "            key = self.fnames[index]\n",
    "            if t == \"Filename\":\n",
    "                target.append(self.fnames[index])\n",
    "            elif t == \"LargeIndex\":\n",
    "                # Traces are sorted by cross-sectional area\n",
    "                # Largest (diastolic) frame is last\n",
    "                target.append(np.int(self.frames[key][-1]))\n",
    "            elif t == \"SmallIndex\":\n",
    "                # Largest (diastolic) frame is first\n",
    "                target.append(np.int(self.frames[key][0]))\n",
    "            elif t == \"LargeFrame\":\n",
    "                target.append(video[:, self.frames[key][-1], :, :])\n",
    "            elif t == \"SmallFrame\":\n",
    "                target.append(video[:, self.frames[key][0], :, :])\n",
    "            elif t in [\"LargeTrace\", \"SmallTrace\"]:\n",
    "                if t == \"LargeTrace\":\n",
    "                    t = self.trace[key][self.frames[key][-1]]\n",
    "                else:\n",
    "                    t = self.trace[key][self.frames[key][0]]\n",
    "                x1, y1, x2, y2 = t[:, 0], t[:, 1], t[:, 2], t[:, 3]\n",
    "                x = np.concatenate((x1[1:], np.flip(x2[1:])))\n",
    "                y = np.concatenate((y1[1:], np.flip(y2[1:])))\n",
    "\n",
    "                r, c = skimage.draw.polygon(np.rint(y).astype(np.int64), np.rint(x).astype(np.int64), (video.shape[2], video.shape[3]))\n",
    "                mask = np.zeros((video.shape[2], video.shape[3]), np.float32)\n",
    "                mask[r, c] = 1\n",
    "                target.append(mask)\n",
    "            else:\n",
    "                if self.split == \"CLINICAL_TEST\" or self.split == \"EXTERNAL_TEST\":\n",
    "                    target.append(np.float32(0))\n",
    "                else:\n",
    "                    target.append(np.float32(self.outcome[index][self.header.index(t)]))\n",
    "\n",
    "        if target != []:\n",
    "            target = tuple(target) if len(target) > 1 else target[0]\n",
    "            if self.target_transform is not None:\n",
    "                target = self.target_transform(target)\n",
    "\n",
    "        # Select clips from video\n",
    "        video = tuple(video[:, s + self.period * np.arange(length), :, :] for s in start)\n",
    "        if self.clips == 1:\n",
    "            video = video[0]\n",
    "        else:\n",
    "            video = np.stack(video)\n",
    "\n",
    "        if self.pad is not None:\n",
    "            # Add padding of zeros (mean color of videos)\n",
    "            # Crop of original size is taken out\n",
    "            # (Used as augmentation)\n",
    "            c, l, h, w = video.shape\n",
    "            temp = np.zeros((c, l, h + 2 * self.pad, w + 2 * self.pad), dtype=video.dtype)\n",
    "            temp[:, :, self.pad:-self.pad, self.pad:-self.pad] = video  # pylint: disable=E1130\n",
    "            i, j = np.random.randint(0, 2 * self.pad, 2)\n",
    "            video = temp[:, :, i:(i + h), j:(j + w)]\n",
    "\n",
    "        return video, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        lines = [\"Target type: {target_type}\", \"Split: {split}\"]\n",
    "        return '\\n'.join(lines).format(**self.__dict__)\n",
    "\n",
    "\n",
    "def _defaultdict_of_lists():\n",
    "    return collections.defaultdict(list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_mean_and_std(dataset: torch.utils.data.Dataset,\n",
    "                     samples: int = 128,\n",
    "                     batch_size: int = 8,\n",
    "                     num_workers: int = 4):\n",
    "\n",
    "\n",
    "    if samples is not None and len(dataset) > samples:\n",
    "        indices = np.random.choice(len(dataset), samples, replace=False)\n",
    "        dataset = torch.utils.data.Subset(dataset, indices)\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "    n = 0\n",
    "    s1 = 0.\n",
    "    s2 = 0.\n",
    "    for (x, *_) in tqdm.tqdm(dataloader):\n",
    "        x = x.transpose(0, 1).contiguous().view(3, -1)\n",
    "        n += x.shape[1]\n",
    "        s1 += torch.sum(x, dim=1).numpy()\n",
    "        s2 += torch.sum(x ** 2, dim=1).numpy()\n",
    "    mean = s1 / n  # type: np.ndarray\n",
    "    std = np.sqrt(s2 / n - mean ** 2)  # type: np.ndarray\n",
    "\n",
    "    mean = mean.astype(np.float32)\n",
    "    std = std.astype(np.float32)\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "def ef_run_epoch(model, dataloader, train, optim, device, save_all=False, block_size=None):\n",
    "\n",
    "\n",
    "    model.train(train)\n",
    "\n",
    "    total = 0  # total training loss\n",
    "    n = 0      # number of videos processed\n",
    "    s1 = 0     # sum of ground truth EF\n",
    "    s2 = 0     # Sum of ground truth EF squared\n",
    "\n",
    "    yhat = []\n",
    "    y = []\n",
    "\n",
    "    with torch.set_grad_enabled(train):\n",
    "        with tqdm.tqdm(total=len(dataloader)) as pbar:\n",
    "            for (X, outcome) in dataloader:\n",
    "                # X = torch.flip(X, (4,))\n",
    "                # X = X[:, :, :, ::-1, :]\n",
    "\n",
    "                y.append(outcome.numpy())\n",
    "                X = X.to(device)\n",
    "                outcome = outcome.to(device)\n",
    "\n",
    "                average = (len(X.shape) == 6)\n",
    "                if average:\n",
    "                    batch, n_clips, c, f, h, w = X.shape\n",
    "                    X = X.view(-1, c, f, h, w)\n",
    "\n",
    "                s1 += outcome.sum()\n",
    "                s2 += (outcome ** 2).sum()\n",
    "\n",
    "                if block_size is None:\n",
    "                    outputs = model(X)\n",
    "                else:\n",
    "                    outputs = torch.cat([model(X[j:(j + block_size), ...]) for j in range(0, X.shape[0], block_size)])\n",
    "\n",
    "                if save_all:\n",
    "                    yhat.append(outputs.view(-1).to(\"cpu\").detach().numpy())\n",
    "\n",
    "                if average:\n",
    "                    outputs = outputs.view(batch, n_clips, -1).mean(1)\n",
    "\n",
    "                if not save_all:\n",
    "                    yhat.append(outputs.view(-1).to(\"cpu\").detach().numpy())\n",
    "\n",
    "                loss = torch.nn.functional.mse_loss(outputs.view(-1), outcome.type(torch.float32))\n",
    "\n",
    "                if train:\n",
    "                    optim.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optim.step()\n",
    "\n",
    "                total += loss.item() * X.size(0)\n",
    "                n += X.size(0)\n",
    "\n",
    "                pbar.set_postfix_str(\"{:.2f} ({:.2f}) / {:.2f}\".format(total / n, loss.item(), s2 / n - (s1 / n) ** 2))\n",
    "                pbar.update()\n",
    "\n",
    "    if not save_all:\n",
    "        yhat = np.concatenate(yhat)\n",
    "    y = np.concatenate(y)\n",
    "\n",
    "    return total / n, yhat, y\n",
    "\n",
    "def collate_fn(x):\n",
    "    x, f = zip(*x)\n",
    "    i = list(map(lambda t: t.shape[1], x))\n",
    "    x = torch.as_tensor(np.swapaxes(np.concatenate(x, 1), 0, 1))\n",
    "    return x, f, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3h8FWtfkUyG2",
    "outputId": "42980778-bc8a-4c97-bbdb-872efe65c7f7"
   },
   "outputs": [],
   "source": [
    "# Download model weights\n",
    "DestinationForWeights = '.'\n",
    "if os.path.exists(DestinationForWeights):\n",
    "    print(\"The weights are at\", DestinationForWeights)\n",
    "else:\n",
    "    print(\"Creating folder at \", DestinationForWeights, \" to store weights\")\n",
    "    os.mkdir(DestinationForWeights)\n",
    "\n",
    "segmentationWeightsURL = 'https://github.com/douyang/EchoNetDynamic/releases/download/v1.0.0/deeplabv3_resnet50_random.pt'\n",
    "ejectionFractionWeightsURL = 'https://github.com/douyang/EchoNetDynamic/releases/download/v1.0.0/r2plus1d_18_32_2_pretrained.pt'\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(DestinationForWeights, os.path.basename(segmentationWeightsURL))):\n",
    "    print(\"Downloading Segmentation Weights, \", segmentationWeightsURL,\" to \",os.path.join(DestinationForWeights,os.path.basename(segmentationWeightsURL)))\n",
    "    filename = wget.download(segmentationWeightsURL, out = DestinationForWeights)\n",
    "else:\n",
    "    print(\"Segmentation Weights already present\")\n",
    "\n",
    "if not os.path.exists(os.path.join(DestinationForWeights, os.path.basename(ejectionFractionWeightsURL))):\n",
    "    print(\"Downloading EF Weights, \", ejectionFractionWeightsURL,\" to \",os.path.join(DestinationForWeights,os.path.basename(ejectionFractionWeightsURL)))\n",
    "    filename = wget.download(ejectionFractionWeightsURL, out = DestinationForWeights)\n",
    "else:\n",
    "    print(\"EF Weights already present\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9Zzc6E8Uig3",
    "outputId": "12b3cc37-ef05-4e62-c3d2-91c2ed024f08"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-13cff57b59f0>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(DestinationForWeights, os.path.basename(ejectionFractionWeightsURL)), map_location = \"cuda\")\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 169MB/s]\n",
      "<ipython-input-5-13cff57b59f0>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(os.path.basename(segmentationWeightsURL )), map_location = \"cuda\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = 32\n",
    "period = 1 #2\n",
    "batch_size = 20\n",
    "ef_model = torchvision.models.video.r2plus1d_18(pretrained=False)\n",
    "ef_model.fc = torch.nn.Linear(ef_model.fc.in_features, 1)\n",
    "device = torch.device(\"cuda\")\n",
    "checkpoint = torch.load(os.path.join(DestinationForWeights, os.path.basename(ejectionFractionWeightsURL)), map_location = \"cuda\")\n",
    "state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "ef_model.load_state_dict(state_dict_cpu)\n",
    "\n",
    "seg_model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=False)\n",
    "seg_model.classifier[-1] = torch.nn.Conv2d(seg_model.classifier[-1].in_channels, 1, kernel_size=seg_model.classifier[-1].kernel_size)\n",
    "\n",
    "checkpoint = torch.load(os.path.join(os.path.basename(segmentationWeightsURL )), map_location = \"cuda\")\n",
    "state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "seg_model.load_state_dict(state_dict_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the directory named input_folder\n",
    "\n",
    "the input folder should contain only one avi file\n",
    "```\n",
    "input_folder\n",
    "-video.avi\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "bun4SH8QVgow"
   },
   "outputs": [],
   "source": [
    "def model_predict(seg_model,ef_model, video_seg_folder, device=(\"cuda\" if torch.cuda.is_available() else 'cpu')):\n",
    "    mean = np.array([45.851063, 45.81058,  45.800232])\n",
    "    std = np.array([53.756863, 53.732307 ,53.68092 ])\n",
    "    kwargs = {\"mean\": mean,\n",
    "          \"std\": std,\n",
    "          \"length\": None,\n",
    "          \"period\": 1,\n",
    "          }\n",
    "\n",
    "    ds = Echo(split=\"external_test\", external_test_location = video_seg_folder, target_type=[\"Filename\"], **kwargs)\n",
    "    dataloader = torch.utils.data.DataLoader(ds,batch_size=1, num_workers=0, shuffle=False, pin_memory=(device == \"cuda\"), collate_fn=collate_fn)\n",
    "    block = 1024\n",
    "    seg_model.eval()\n",
    "    ef_model.eval()\n",
    "    seg_model.to(device)\n",
    "    ef_model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for (z, f, i) in tqdm.tqdm(dataloader):\n",
    "            z = z.to(device)\n",
    "            y_out = np.concatenate([seg_model(z[i:(i + block), :, :, :])[\"out\"].detach().cpu().numpy() for i in range(0, z.shape[0], block)]).astype(np.float16)\n",
    "            print(\"Y shape: \",y_out.shape)\n",
    "            print(\"X Shape :\", z.shape)\n",
    "    ds = Echo(split = \"external_test\", external_test_location = video_seg_folder, target_type=[\"EF\"], **kwargs)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(ds, batch_size = 1, num_workers = 5, shuffle = True, pin_memory=(device == \"cuda\"))\n",
    "\n",
    "    loss, yhat, y = ef_run_epoch(ef_model, test_dataloader, False, None, device, save_all=True, block_size=25)\n",
    "\n",
    "    return y_out, yhat[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUIhQVSxV5cq",
    "outputId": "4b1c5b7d-520b-4fd3-92fd-9a722c642981"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape:  (140, 1, 112, 112)\n",
      "X Shape : torch.Size([140, 3, 112, 112])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s, 3617.05 (3617.05) / 0.00]\n"
     ]
    }
   ],
   "source": [
    "y, ef = model_predict(seg_model,ef_model, 'input_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "5Xq5sd7YVuxx"
   },
   "outputs": [],
   "source": [
    "def save_mask(y,model, video_seg_folder, output_folder):\n",
    "    dataloader = torch.utils.data.DataLoader(Echo(split=\"external_test\", external_test_location=video_seg_folder, target_type=[\"Filename\"], length=None, period=1),\n",
    "                                         batch_size=1, num_workers=4, shuffle=False, pin_memory=False)\n",
    "    for (x, filename) in tqdm.tqdm(dataloader):\n",
    "        x = x.numpy()\n",
    "\n",
    "        for i in range(len(filename)):\n",
    "            img = x[i, :, :, :, :].copy()\n",
    "            logit = y[:,0,:,:]\n",
    "            img[1, :, :, :] = img[0, :, :, :]\n",
    "            img[2, :, :, :] = img[0, :, :, :]\n",
    "\n",
    "            img[0, :, :, :] = np.maximum(255. * (logit > 0.5), img[0, :, :,:])\n",
    "\n",
    "            # Create a mask video frame\n",
    "            mask_img = img.astype(np.uint8)\n",
    "\n",
    "            savevideo(os.path.join(f\"{output_folder}/mask.mp4\"), mask_img, 50)\n",
    "            return mask_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1e2IdnCXYzN",
    "outputId": "5ef3003e-702c-40a5-e6a9-0ef8a1e70464"
   },
   "outputs": [],
   "source": [
    "nik = save_mask(y,seg_model,input_folder, input_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This will save a Mask segmented video in the input folder, you can see the segmentation result there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HF31k0ZDCuPO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
